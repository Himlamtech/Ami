"""Orchestration result domain entity."""

from dataclasses import dataclass, field
from datetime import datetime
from typing import Dict, Any, List, Optional
from app.domain.entities.tool_call import ToolCall
from app.domain.enums.tool_type import ToolType


@dataclass
class VectorSearchReference:
    """
    Value object: Vector search results as reference information.

    IMPORTANT: This is REFERENCE data for the orchestrator, NOT hard rules.
    The orchestrator (LLM) uses this information to make decisions,
    but it can override based on context understanding.
    """

    max_score: float = 0.0
    top_chunks: List[str] = field(default_factory=list)
    chunk_contents: List[Dict[str, Any]] = field(default_factory=list)
    search_time_ms: int = 0

    def to_dict(self) -> Dict[str, Any]:
        return {
            "max_score": self.max_score,
            "top_chunks": self.top_chunks,
            "chunk_count": len(self.top_chunks),
            "search_time_ms": self.search_time_ms,
        }

    def has_results(self) -> bool:
        """Check if vector search returned results."""
        return len(self.top_chunks) > 0

    def is_high_confidence(self, threshold: float = 0.7) -> bool:
        """
        Check if max score indicates high confidence.

        Note: This is just a helper, orchestrator makes final decision.
        """
        return self.max_score >= threshold


@dataclass
class OrchestrationMetrics:
    """Value object: Performance metrics for orchestration."""

    total_time_ms: int = 0
    orchestrator_decision_time_ms: int = 0
    tools_execution_time_ms: int = 0
    synthesis_time_ms: int = 0

    def to_dict(self) -> Dict[str, Any]:
        return {
            "total_time_ms": self.total_time_ms,
            "orchestrator_decision_time_ms": self.orchestrator_decision_time_ms,
            "tools_execution_time_ms": self.tools_execution_time_ms,
            "synthesis_time_ms": self.synthesis_time_ms,
        }


@dataclass
class OrchestrationResult:
    """
    Domain Entity: Result of query orchestration with function calling.

    Aggregates:
    - Original query and context
    - Vector search results (reference information)
    - LLM orchestrator's tool decisions
    - Tool execution outcomes
    - Synthesized final answer

    Business Rules:
    1. At least one tool should be called (even if it's answer_directly)
    2. All tool calls must complete before synthesis
    3. Final answer is generated by synthesizing tool results
    """

    # Identity
    id: str
    session_id: str
    message_id: str  # Link to the user message that triggered this

    # Original query
    query: str
    user_context: Dict[str, Any] = field(default_factory=dict)

    # Vector search reference (NOT hard rules!)
    vector_reference: VectorSearchReference = field(
        default_factory=VectorSearchReference
    )

    # Orchestrator decisions
    tools_called: List[ToolCall] = field(default_factory=list)
    orchestrator_reasoning: str = ""
    orchestrator_model: str = ""  # Which model made the decision

    # Final synthesis
    final_answer: str = ""
    confidence_level: str = "medium"  # high, medium, low
    sources_used: List[str] = field(default_factory=list)  # rag, web, direct, form

    # Metrics
    metrics: OrchestrationMetrics = field(default_factory=OrchestrationMetrics)

    # Audit
    created_at: datetime = field(default_factory=datetime.now)
    completed_at: Optional[datetime] = None

    # Business Logic Methods

    def add_tool_call(self, tool_call: ToolCall) -> None:
        """Add a tool call to this orchestration."""
        self.tools_called.append(tool_call)

    def get_successful_tools(self) -> List[ToolCall]:
        """Get all successfully executed tools."""
        return [t for t in self.tools_called if t.is_success()]

    def get_failed_tools(self) -> List[ToolCall]:
        """Get all failed tools."""
        return [t for t in self.tools_called if t.is_failed()]

    def has_tool_type(self, tool_type: ToolType) -> bool:
        """Check if a specific tool type was called."""
        return any(t.tool_type == tool_type for t in self.tools_called)

    def get_tool_by_type(self, tool_type: ToolType) -> Optional[ToolCall]:
        """Get tool call by type."""
        for t in self.tools_called:
            if t.tool_type == tool_type:
                return t
        return None

    def all_tools_completed(self) -> bool:
        """Check if all tools have completed execution."""
        return all(t.is_completed() for t in self.tools_called)

    def any_tool_failed(self) -> bool:
        """Check if any tool failed."""
        return any(t.is_failed() for t in self.tools_called)

    def set_final_answer(
        self,
        answer: str,
        confidence: str = "medium",
        sources: Optional[List[str]] = None,
    ) -> None:
        """
        Set the final synthesized answer.

        Args:
            answer: The final answer text
            confidence: Confidence level (high, medium, low)
            sources: List of sources used (rag, web, direct, form)
        """
        self.final_answer = answer
        self.confidence_level = confidence
        if sources:
            self.sources_used = sources
        self.completed_at = datetime.now()

    def mark_completed(self) -> None:
        """Mark orchestration as completed."""
        self.completed_at = datetime.now()

        # Calculate metrics
        if self.created_at and self.completed_at:
            delta = self.completed_at - self.created_at
            self.metrics.total_time_ms = int(delta.total_seconds() * 1000)

        # Sum tool execution times
        self.metrics.tools_execution_time_ms = sum(
            t.execution_time_ms or 0 for t in self.tools_called
        )

    def used_rag(self) -> bool:
        """Check if RAG was used."""
        return self.has_tool_type(ToolType.USE_RAG_CONTEXT)

    def used_web_search(self) -> bool:
        """Check if web search was used."""
        return self.has_tool_type(ToolType.SEARCH_WEB)

    def used_form_generation(self) -> bool:
        """Check if form generation was used."""
        return self.has_tool_type(ToolType.FILL_FORM)

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for serialization."""
        return {
            "id": self.id,
            "session_id": self.session_id,
            "message_id": self.message_id,
            "query": self.query,
            "user_context": self.user_context,
            "vector_reference": self.vector_reference.to_dict(),
            "tools_called": [t.to_dict() for t in self.tools_called],
            "orchestrator_reasoning": self.orchestrator_reasoning,
            "orchestrator_model": self.orchestrator_model,
            "final_answer": self.final_answer,
            "confidence_level": self.confidence_level,
            "sources_used": self.sources_used,
            "metrics": self.metrics.to_dict(),
            "created_at": self.created_at.isoformat(),
            "completed_at": (
                self.completed_at.isoformat() if self.completed_at else None
            ),
        }

    def to_summary_dict(self) -> Dict[str, Any]:
        """Convert to summary dict (for API response)."""
        return {
            "id": self.id,
            "tools_used": [
                t.tool_type.value for t in self.tools_called if t.is_success()
            ],
            "confidence": self.confidence_level,
            "sources": self.sources_used,
            "total_time_ms": self.metrics.total_time_ms,
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "OrchestrationResult":
        """Create OrchestrationResult from dictionary."""
        vector_ref_data = data.get("vector_reference", {})
        metrics_data = data.get("metrics", {})

        return cls(
            id=data["id"],
            session_id=data["session_id"],
            message_id=data["message_id"],
            query=data["query"],
            user_context=data.get("user_context", {}),
            vector_reference=VectorSearchReference(
                max_score=vector_ref_data.get("max_score", 0.0),
                top_chunks=vector_ref_data.get("top_chunks", []),
                search_time_ms=vector_ref_data.get("search_time_ms", 0),
            ),
            tools_called=[ToolCall.from_dict(t) for t in data.get("tools_called", [])],
            orchestrator_reasoning=data.get("orchestrator_reasoning", ""),
            orchestrator_model=data.get("orchestrator_model", ""),
            final_answer=data.get("final_answer", ""),
            confidence_level=data.get("confidence_level", "medium"),
            sources_used=data.get("sources_used", []),
            metrics=OrchestrationMetrics(
                total_time_ms=metrics_data.get("total_time_ms", 0),
                orchestrator_decision_time_ms=metrics_data.get(
                    "orchestrator_decision_time_ms", 0
                ),
                tools_execution_time_ms=metrics_data.get("tools_execution_time_ms", 0),
                synthesis_time_ms=metrics_data.get("synthesis_time_ms", 0),
            ),
            created_at=(
                datetime.fromisoformat(data["created_at"])
                if data.get("created_at")
                else datetime.now()
            ),
            completed_at=(
                datetime.fromisoformat(data["completed_at"])
                if data.get("completed_at")
                else None
            ),
        )

    def __repr__(self) -> str:
        tools = [t.tool_type.value for t in self.tools_called]
        return f"OrchestrationResult(tools={tools}, confidence={self.confidence_level})"
